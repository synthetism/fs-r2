/**
 * Cloudflare R2 FileSystem Demo
 * 
 * This demo showcases the Cloudflare R2 S3-compatible FileSystem capabilities using real cloud storage.
 * 
 * Usage:
 *   npm run build
 *   node examples/r2-demo.js
 */

import { createCloudflareR2FileSystem, type CloudflareR2Options } from '../src/r2';
import * as fs from 'fs';
import * as path from 'path';
import { fileURLToPath } from 'url';

const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);

async function runR2Demo() {
  console.log('ğŸš€ SYNET FS - Cloudflare R2 Demo\n');

  try {
    // Load credentials
    const testConfigPath = path.join(__dirname, '../private/r2-test-access.json');
    const testConfig = JSON.parse(fs.readFileSync(testConfigPath, 'utf8'));

    console.log(`ğŸ“ Bucket: ${testConfig.bucket}`);
    console.log(`ğŸ”— Access Key: ${testConfig.name}`);
    console.log(`ğŸ”‘ Using S3-compatible API authentication\n`);

    // Initialize Cloudflare R2 FileSystem
    const r2Options: CloudflareR2Options = {
      accountId: testConfig.accountId, // Use correct account ID from config
      accessKeyId: testConfig.accessKeyId,
      secretAccessKey: testConfig.secretAccessKey,
      bucket: testConfig.bucket,
      region: 'auto',
      prefix: 'demo' // Use demo prefix
    };

    const r2FS = createCloudflareR2FileSystem(r2Options);
    console.log('âœ… Cloudflare R2 FileSystem initialized\n');

    // Demo 1: Simple file operations
    console.log('ğŸ“„ Demo 1: Basic File Operations');
    const textFile = `demo-text-${Date.now()}.txt`;
    const textContent = `Hello Cloudflare R2 from SYNET FS!\n\nThis is a demonstration of the R2 S3-compatible adapter.\nTimestamp: ${new Date().toISOString()}\n\nFeatures:\n- S3-compatible API\n- Global edge network\n- Zero egress fees\n- Built for performance`;
    
    await r2FS.writeFile(textFile, textContent);
    console.log(`  âœ… Wrote: ${textFile}`);
    
    const readContent = await r2FS.readFile(textFile);
    console.log(`  âœ… Read: ${readContent.length} bytes`);
    console.log(`  ğŸ“– Preview: "${readContent.substring(0, 50)}..."\n`);

    // Demo 2: JSON file handling
    console.log('ğŸ“„ Demo 2: JSON File Operations');
    const jsonFile = `demo-data-${Date.now()}.json`;
    const jsonData = {
      project: 'SYNET FS',
      adapter: 'Cloudflare R2',
      timestamp: Date.now(),
      features: ['S3-compatible API', 'global edge network', 'zero egress fees', 'async operations'],
      performance: {
        upload: 'fast',
        download: 'cached',
        concurrent: 'supported',
        edge: 'global'
      },
      cloudflare: {
        provider: 'Cloudflare',
        service: 'R2',
        region: 'auto',
        compatibility: 'S3'
      }
    };
    
    await r2FS.writeFile(jsonFile, JSON.stringify(jsonData, null, 2));
    console.log(`  âœ… Wrote JSON: ${jsonFile}`);
    
    const readJsonContent = await r2FS.readFile(jsonFile);
    const parsedData = JSON.parse(readJsonContent);
    console.log(`  âœ… Read and parsed JSON successfully`);
    console.log(`  ğŸ“Š Features: ${parsedData.features.join(', ')}\n`);

    // Demo 3: Directory operations
    console.log('ğŸ“‚ Demo 3: Directory Operations');
    const baseDir = `demo-directory-${Date.now()}`;
    
    // Create nested file structure
    await r2FS.writeFile(`${baseDir}/readme.md`, '# Demo Directory\n\nThis directory contains demo files for Cloudflare R2.');
    await r2FS.writeFile(`${baseDir}/config.json`, '{"setting": "demo", "provider": "cloudflare-r2"}');
    await r2FS.writeFile(`${baseDir}/logs/app.log`, 'Demo log entry 1 - R2 upload\nDemo log entry 2 - S3 compatible');
    await r2FS.writeFile(`${baseDir}/data/users.json`, '[{"id": 1, "name": "Demo User", "storage": "R2"}]');
    await r2FS.writeFile(`${baseDir}/assets/style.css`, 'body { font-family: sans-serif; }');
    
    console.log(`  âœ… Created nested file structure in: ${baseDir}`);
    
    // List directory contents
    const contents = await r2FS.readDir(baseDir);
    console.log(`  ğŸ“‚ Directory contents: ${contents.join(', ')}`);
    
    // List subdirectory
    const logContents = await r2FS.readDir(`${baseDir}/logs`);
    console.log(`  ğŸ“ Logs directory: ${logContents.join(', ')}\n`);

    // Demo 4: File statistics
    console.log('ğŸ“Š Demo 4: File Statistics');
    const stats = await r2FS.stat(textFile);
    console.log(`  ğŸ“ File size: ${stats.size} bytes`);
    console.log(`  ğŸ•’ Modified: ${stats.mtime.toISOString()}`);
    console.log(`  ğŸ“„ Is file: ${stats.isFile()}`);
    console.log(`  ğŸ“ Is directory: ${stats.isDirectory()}\n`);

    // Demo 5: Concurrent operations
    console.log('âš¡ Demo 5: Concurrent Operations');
    const concurrentPromises: Promise<void>[] = [];
    const concurrentBase = Date.now();
    
    for (let i = 0; i < 8; i++) {
      const fileName = `concurrent-demo-${concurrentBase}-${i}.txt`;
      const content = `Concurrent file ${i}\nUploaded to Cloudflare R2 at: ${new Date().toISOString()}\nEdge network performance test`;
      concurrentPromises.push(r2FS.writeFile(fileName, content));
    }
    
    const startTime = Date.now();
    await Promise.all(concurrentPromises);
    const duration = Date.now() - startTime;
    
    console.log(`  âœ… Uploaded 8 files concurrently in ${duration}ms\n`);

    // Demo 6: Cache performance
    console.log('ğŸ—„ï¸  Demo 6: Cache Performance');
    const cacheFile = `cache-demo-${Date.now()}.txt`;
    const cacheContent = 'This file will be cached for R2 performance testing.';
    
    await r2FS.writeFile(cacheFile, cacheContent);
    
    // First read (will cache)
    const readStart1 = Date.now();
    await r2FS.readFile(cacheFile);
    const readTime1 = Date.now() - readStart1;
    
    // Second read (from cache)
    const readStart2 = Date.now();
    await r2FS.readFile(cacheFile);
    const readTime2 = Date.now() - readStart2;
    
    console.log(`  ğŸ“– First read: ${readTime1}ms (network + cache)`);
    console.log(`  ğŸ“– Second read: ${readTime2}ms (cache only)`);
    
    if (readTime2 < readTime1) {
      console.log(`  ğŸš€ Cache improved performance by ${((readTime1 - readTime2) / readTime1 * 100).toFixed(1)}%\n`);
    }

    // Demo 7: Bucket information
    console.log('â„¹ï¸  Demo 7: Bucket Information');
    const bucketInfo = r2FS.getBucketInfo();
    console.log(`  ğŸ“ Bucket: ${bucketInfo.bucket}`);
    console.log(`  ğŸ“‚ Prefix: ${bucketInfo.prefix}`);
    console.log(`  ğŸŒ Region: ${bucketInfo.region}`);
    console.log(`  ğŸ†” Account ID: ${bucketInfo.accountId}`);
    
    if (bucketInfo.endpoint) {
      console.log(`  ğŸŒ Endpoint: ${bucketInfo.endpoint}`);
    }
    console.log();

    // Demo 8: S3 compatibility verification
    console.log('ğŸ”— Demo 8: S3 Compatibility Verification');
    const s3TestFile = `s3-compat-test-${Date.now()}.json`;
    const s3TestData = {
      compatibility: 'S3',
      service: 'Cloudflare R2',
      operations: {
        putObject: 'supported',
        getObject: 'supported',
        deleteObject: 'supported',
        listObjects: 'supported',
        headObject: 'supported'
      },
      features: {
        multipartUpload: 'supported',
        versioning: 'available',
        lifecycle: 'available',
        cors: 'supported'
      }
    };
    
    await r2FS.writeFile(s3TestFile, JSON.stringify(s3TestData, null, 2));
    const s3TestResult = await r2FS.readFile(s3TestFile);
    const s3ParsedData = JSON.parse(s3TestResult);
    
    console.log(`  âœ… S3 compatibility verified`);
    console.log(`  ğŸ“‹ Operations: ${Object.keys(s3ParsedData.operations).join(', ')}`);
    console.log(`  ğŸ”§ Features: ${Object.keys(s3ParsedData.features).join(', ')}\n`);

    // Cleanup
    console.log('ğŸ§¹ Demo Cleanup');
    const cleanupFiles = [
      textFile,
      jsonFile,
      cacheFile,
      s3TestFile,
      ...Array.from({length: 8}, (_, i) => `concurrent-demo-${concurrentBase}-${i}.txt`)
    ];
    
    for (const file of cleanupFiles) {
      try {
        await r2FS.deleteFile(file);
        console.log(`  âœ… Deleted: ${file}`);
      } catch (error) {
        console.log(`  âš ï¸  Could not delete ${file}: ${(error as Error).message}`);
      }
    }
    
    // Delete demo directory
    try {
      await r2FS.deleteDir(baseDir);
      console.log(`  âœ… Deleted directory: ${baseDir}`);
    } catch (error) {
      console.log(`  âš ï¸  Could not delete directory ${baseDir}: ${(error as Error).message}`);
    }

    console.log('\nğŸ‰ Cloudflare R2 Demo completed successfully!');
    console.log('\nğŸ“š Summary of demonstrated features:');
    console.log('  âœ… File read/write operations');
    console.log('  âœ… JSON file handling');
    console.log('  âœ… Directory operations and listing');
    console.log('  âœ… File statistics and metadata');
    console.log('  âœ… Concurrent operations (8 files)');
    console.log('  âœ… Performance caching');
    console.log('  âœ… Bucket information access');
    console.log('  âœ… S3 compatibility verification');
    console.log('  âœ… Cleanup and deletion');
    console.log('\nğŸŒŸ Cloudflare R2 features showcased:');
    console.log('  ğŸš€ S3-compatible API');
    console.log('  ğŸŒ Global edge network');
    console.log('  ğŸ’° Zero egress fees');
    console.log('  âš¡ High performance');

  } catch (error) {
    console.error('âŒ Demo failed:', error);
    process.exit(1);
  }
}

// Run the demo
runR2Demo().catch(console.error);
